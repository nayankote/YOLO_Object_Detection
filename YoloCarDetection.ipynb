{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YoloCarDetection",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoKsoF8Ivbll3Dvdb1VPFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nayankote/YOLO_Object_Detection/blob/master/YoloCarDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Voh7QDZmh4",
        "colab_type": "text"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf29vv-8Wpmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.models import load_model, Model\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import scipy.io\n",
        "from matplotlib.pyplot import imshow\n",
        "import os\n",
        "import colorsys\n",
        "import random\n",
        "import imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmD2SZ-GHmiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPsRHXeirZ_S",
        "colab_type": "text"
      },
      "source": [
        "#Filtering relevant boxes, scores and classes\n",
        "This function takes the following input - \\\n",
        "Box confidence (here box refers to a member of a set of predefined,\n",
        "in this case, 5 anchor boxes) is the probability of a cell being a part of a box. \\\n",
        "Boxes - The box parameters (x_center, y_center, height, width) for the box corresponding to each cell. \\\n",
        "box_class_probs - The probability that one among the selected classes (in this case 80) is present in the cell. \\\n",
        "Threshold - A cut off score \n",
        "\n",
        "This function then calculates - \\\n",
        "The scores of each box which is box_confidence*box_class_probs \\\n",
        "The box_class which is the class with highest score for the 5 boxes \\\n",
        "The box_class_score which is the score corresponding to the class found above\n",
        "\n",
        "It then creates a mask where it checks if the box_class_score are above the threshold, applies this mask to the three parameters above and returns the filtered scores, boxes and classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-j-uBrIW3r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_boxes(box_confidence, boxes, box_class_probs, threshold):\n",
        "  #box_confidence (19,19,5,1) -> pc is given \n",
        "  #boxes (19,19,5,4) -> bx,by,h,w is given\n",
        "  #box_class_probs (19,19,5,80) -> the probabilities of the cell containing on of the 80 classes \n",
        "  #threshold -> the number by which the box_class_probs are filtered\n",
        "\n",
        "  box_scores = box_confidence*box_class_probs # (19,19,5,80) gives Pc*Ci\n",
        "  box_class = K.argmax(box_scores, axis = -1) # (19,19,5) gives which class has highest score for each of the 5 boxes\n",
        "  box_class_score = K.max(box_scores, axis = -1) # (19,19,5) gives the highest score of the class for each of the 5 boxes\n",
        "  print(box_class_score)\n",
        "  \n",
        "  mask = (box_class_score >= threshold) # (19,19,5) gives whether the highest score crosses the threshold\n",
        "  print(mask)\n",
        "  scores = tf.boolean_mask(box_class_score, mask, axis = None, name='scores') #(19,19,?)\n",
        "  boxes = tf.boolean_mask(boxes, mask, axis=None, name='boxes') # (19,19,?,4)\n",
        "  classes = tf.boolean_mask(box_class, mask, axis= None, name='classes') # (19,19,?)\n",
        "\n",
        "  return scores, boxes, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE3Y4CB4Vc1Y",
        "colab_type": "text"
      },
      "source": [
        "#non max suppression\n",
        "A lot of cells detect boxes for the same object and a cluster of boxes will often be found around prominent objects. \\\n",
        "Non max suppression is the process of keeping the most prominent box and discarding the rest in the cluster of boxes on a object using the concept of Intersection Over Union (IOU). \\\n",
        "Here is how IOU would work - \\\n",
        "\n",
        "```\n",
        "  **(Input box1, box2)** \n",
        "  (xu1,yu1),(xl1,yl1) = box1 \n",
        "  (xu2,yu2),(xl2,yl2) = box2 \n",
        "\n",
        "  xui = max(xu1,xu2)  \n",
        "  yui = max(yu1,yu2) \n",
        "  xli = min(xl1,xl2) \n",
        "  yli = min(yl1,yl2) \n",
        "\n",
        "  inter_height = yli-yui  \n",
        "  inter_width = xli-xui \n",
        "  inter_area = max(inter_height,0) x max(inter_width,0) \n",
        "\n",
        "  box1_area = (xl1-xu1)x(yl1-yu1) \n",
        "  box2_area = (xl2-xu2)x(yl2-yu2) \n",
        "  total_area = box1_area + box2_area - inter_area \n",
        "\n",
        "  iou = inter_area/total_area \n",
        "```\n",
        "\n",
        "\n",
        "But there exists a built in function in tensorflow.image and we shall make use of that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6LUSiIhdLE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def non_max_suppression(boxes,scores,classes,max_boxes = 10, iou_threshold = 0.5):\n",
        "  max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n",
        "  K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
        "\n",
        "  nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes,iou_threshold,name='nms_indices')\n",
        "\n",
        "  scores = K.gather(scores, nms_indices)\n",
        "  boxes = K.gather(boxes, nms_indices)\n",
        "  classes = K.gather(classes,nms_indices)\n",
        "\n",
        "  return scores, boxes, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl8cnx6BjRYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def boxes_to_corners(box_xy,box_wh):\n",
        "    box_mins = box_xy - (box_wh / 2.)\n",
        "    box_maxes = box_xy + (box_wh / 2.)\n",
        "\n",
        "    return K.concatenate([\n",
        "        box_mins[..., 1:2],  # y_min\n",
        "        box_mins[..., 0:1],  # x_min\n",
        "        box_maxes[..., 1:2],  # y_max\n",
        "        box_maxes[..., 0:1]  # x_max\n",
        "    ])\n",
        "# I have no clue how this works"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-dOgwip2A2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_boxes(boxes,image_shape):\n",
        "    height = image_shape[0]\n",
        "    width = image_shape[1]\n",
        "    image_dims = K.stack([height,width,height,width])\n",
        "    image_dims = K.reshape(image_dims, [1,4])\n",
        "\n",
        "    return boxes*image_dims"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wo98wqi2Iny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
        "\n",
        "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
        "    boxes = boxes_to_corners(box_xy, box_wh)\n",
        "    scores, boxes, classes = filter_boxes(box_confidence, boxes, box_class_probs, score_threshold)\n",
        "    boxes = scale_boxes(boxes, image_shape)\n",
        "    scores, boxes, classes = non_max_suppression(boxes,scores,classes,max_boxes = 10, iou_threshold = 0.5)\n",
        "\n",
        "    return scores, boxes, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgkZBc80aGUy",
        "colab_type": "text"
      },
      "source": [
        "Reading in the predefined classes (80) and anchor boxes (5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kLBfBpVA5GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_anchors(path):\n",
        "    with open(path) as f:\n",
        "        anchors = f.readline()\n",
        "        anchors = [float(x) for x in anchors.split(\",\")]\n",
        "        anchors = np.array(anchors).reshape(-1,2)\n",
        "    return anchors\n",
        "\n",
        "def read_classes(path):\n",
        "    with open(path) as f:\n",
        "        classes = f.readlines()\n",
        "    classes = [c.strip() for c in classes]\n",
        "    return classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpyAZu9u7hIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(path, model_image_size):\n",
        "    image = Image.open(path)\n",
        "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
        "    image_data = np.array(resized_image, dtype='float32')\n",
        "    image_data /= 255.\n",
        "    image_data = np.expand_dims(image_data,0)\n",
        "    return image, image_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jJEcDh9aVFL",
        "colab_type": "text"
      },
      "source": [
        "Taken from the Coursera Assignment on yolo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdpy6EIllyQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors):\n",
        "    font = ImageFont.truetype(font='/content/drive/My Drive/Colab Notebooks/Yolo Object Detection/FiraMono-Medium (2).otf', size=np.floor(3e-2*image.size[1]+0.5).astype('int32'))\n",
        "    thickness = (image.size[0] + image.size[1])//300\n",
        "\n",
        "    for i,c in reversed(list(enumerate(out_classes))):\n",
        "        predicted_class = class_names[c]\n",
        "        box = out_boxes[i]\n",
        "        score = out_scores[i]\n",
        "\n",
        "        label ='{} {:.2f}'.format(predicted_class,score)\n",
        "\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        label_size = draw.textsize(label, font)\n",
        "\n",
        "        top, left, bottom, right = box\n",
        "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
        "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
        "        print(label, (left, top), (right, bottom))\n",
        "\n",
        "        if top - label_size[1] >= 0:\n",
        "            text_origin = np.array([left, top - label_size[1]])\n",
        "        else:\n",
        "            text_origin = np.array([left, top + 1])\n",
        "\n",
        "        # My kingdom for a good redistributable image drawing library.\n",
        "        for i in range(thickness):\n",
        "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[c])\n",
        "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[c])\n",
        "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "        del draw\n",
        "        \n",
        "def generate_colors(class_names):\n",
        "    hsv_tuples = [(x / len(class_names), 1., 1.) for x in range(len(class_names))]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
        "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
        "    random.seed(None)  # Reset seed to default.\n",
        "    return colors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qjbOO1UaeB0",
        "colab_type": "text"
      },
      "source": [
        "This function takes the output of the yolo model and converts them into tensors of the shape that we need to analyze, find objects and draw boxes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x89vL9CxG1-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''def yolo_head(features, anchors, num_classes):\n",
        "    num_anchors = len(anchors)\n",
        "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2]) #shape (1,1,1,5,2) batch,height,width,5 anchors, 2 dimensions\n",
        "    conv_shape = K.shape(features)[1:3]\n",
        "\n",
        "    height_tensor = K.arange(0, stop = conv_shape[0]) #basically forms a tesor of shape(n)\n",
        "    width_tensor = K.arange(0, stop = conv_shape[1])\n",
        "    height_tensor = K.tile(height_tensor, [conv_shape[1]]) #repeating the height tensor width number of times\n",
        "    width_tensor = K.tile(K.expand_dims(width_tensor, 0), [conv_shape[0],1]) #add one dimension to width and replicate it height times\n",
        "    width_tensor = K.flatten(K.transpose(width_tensor)) #not sure why we do this\n",
        "\n",
        "    conv = K.transpose(K.stack([height_tensor,width_tensor]))\n",
        "    conv = K.reshape(conv, [1, conv_shape[0], conv_shape[1], 1, 2])\n",
        "    conv = K.cast(conv, K.dtype(features))\n",
        "\n",
        "    festures = K.reshape(features, [-1, conv_shape[0], conv_shape[1], num_anchors, num_classes + 5])\n",
        "    conv_shape = K.cast(K.reshape(conv_shape, [1, 1, 1, 1, 2]), K.dtype(features))\n",
        "\n",
        "    box_confidence = K.sigmoid(features[..., 4:5])\n",
        "    box_xy = K.sigmoid(features[..., :2])\n",
        "    box_wh = K.exp(features[..., 2:4])\n",
        "    box_class_probs = K.softmax(features[..., 5:])\n",
        "\n",
        "    box_xy = (box_xy + conv)/conv_shape\n",
        "    box_wh = box_wh * anchors_tensor / conv_shape\n",
        "\n",
        "    return box_confidence, box_xy, box_wh, box_class_probs\n",
        "'''\n",
        "\n",
        "def yolo_head(feats, anchors, num_classes):\n",
        "\n",
        "\n",
        "    num_anchors = len(anchors)\n",
        "    # Reshape to batch, height, width, num_anchors, box_params.\n",
        "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n",
        "    # Static implementation for fixed models.\n",
        "    # TODO: Remove or add option for static implementation.\n",
        "    # _, conv_height, conv_width, _ = K.int_shape(feats)\n",
        "    # conv_dims = K.variable([conv_width, conv_height])\n",
        "\n",
        "    # Dynamic implementation of conv dims for fully convolutional model.\n",
        "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
        "    # In YOLO the height index is the inner most iteration.\n",
        "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
        "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
        "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
        "\n",
        "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
        "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
        "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
        "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
        "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
        "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
        "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
        "    \n",
        "    feats = K.reshape(feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
        "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
        "\n",
        "    # Static generation of conv_index:\n",
        "    # conv_index = np.array([_ for _ in np.ndindex(conv_width, conv_height)])\n",
        "    # conv_index = conv_index[:, [1, 0]]  # swap columns for YOLO ordering.\n",
        "    # conv_index = K.variable(\n",
        "    #     conv_index.reshape(1, conv_height, conv_width, 1, 2))\n",
        "    # feats = Reshape(\n",
        "    #     (conv_dims[0], conv_dims[1], num_anchors, num_classes + 5))(feats)\n",
        "\n",
        "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
        "    box_xy = K.sigmoid(feats[..., :2])\n",
        "    box_wh = K.exp(feats[..., 2:4])\n",
        "    box_class_probs = K.softmax(feats[..., 5:])\n",
        "\n",
        "    # Adjust preditions to each spatial grid point and anchor size.\n",
        "    # Note: YOLO iterates over height index before width index.\n",
        "    box_xy = (box_xy + conv_index) / conv_dims\n",
        "    box_wh = box_wh * anchors_tensor / conv_dims\n",
        "\n",
        "    return box_confidence, box_xy, box_wh, box_class_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Raer7lA-48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anchors = read_anchors(\"/content/drive/My Drive/Colab Notebooks/Yolo Object Detection/anchors.txt\")\n",
        "class_names = read_classes(\"/content/drive/My Drive/Colab Notebooks/Yolo Object Detection/classes80.txt\")\n",
        "yolo_model = load_model(\"/content/drive/My Drive/Colab Notebooks/Yolo Object Detection/yolo.h5\")\n",
        "image_size = (720.,1080.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmwu9uE1Ibgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yolo_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEtcrzOCIynA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = K.get_session()\n",
        "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
        "scores, boxes, classes = yolo_eval(yolo_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbx3SzkzBtbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(sess, image_file):\n",
        "    image, image_data = preprocess_image(\"/content/drive/My Drive/Colab Notebooks/Yolo Object Detection/images/\" + image_file, model_image_size = (608,608))\n",
        "    out_scores, out_boxes, out_classes = sess.run(fetches = [scores,boxes,classes], feed_dict={yolo_model.input: image_data, K.learning_phase() : 0})\n",
        "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
        "    colors = generate_colors(class_names)\n",
        "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
        "    image.save(os.path.join(\"/content/drive/My Drive/Colab Notebooks/Yolo Object Detection/out\", image_file), quality=90)\n",
        "    output_image = imageio.imread(os.path.join(\"/content/drive/My Drive/Colab Notebooks/Yolo Object Detection/out\", image_file))\n",
        "    imshow(output_image)\n",
        "    return out_scores, out_boxes, out_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV1jAlUrB6VQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_scores, out_boxes, out_classes = predict(sess, \"test_bottle.jpeg\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}